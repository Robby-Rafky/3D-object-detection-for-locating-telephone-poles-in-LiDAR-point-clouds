{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyM/JQ0N3wdSctDcLLrFkgda"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NF8ZBca2sMWM"},"outputs":[],"source":["# @title Model training and saving\n","\n","def train_model(save_dir, epochs = 500, train_size = 128, patience = 0):\n","    \"\"\"\n","    Trains a YOLOv5 model on the specified dataset and saves the trained model\n","    to the specified directory.\n","\n","    Parameters:\n","    -----------\n","    save_dir : str\n","        The directory where the trained model and output files will be saved.\n","\n","    epochs : int, optional\n","        The number of training epochs. Default is 500.\n","\n","    train_size : int, optional\n","        The size (width and height) of the input images used for training.\n","        Default is 128.\n","\n","    patience : int, optional\n","        The number of epochs with no improvement after which training will be\n","        stopped early. Set to 0 to disable early stopping. Default is 0.\n","\n","    Returns:\n","    --------\n","    None\n","    \"\"\"\n","\n","    model = YOLO(\"yolov5nu.pt\")\n","\n","    model.train(data=f\"dataset/dataset.yaml\",\n","                epochs=epochs,\n","                imgsz=train_size,\n","                batch=1, name=\"Telefinder_Model\",\n","                patience=patience,\n","                project=f\"Outputs/{save_dir}\")\n","\n","    model.save(f\"Outputs/{save_dir}/Telefinder_Model.pt\")"]},{"cell_type":"code","source":["# @title Bounding Box Drawing\n","\n","def draw_bounding_boxes(save_dir, file_name, detections, encode_type):\n","    \"\"\"\n","    Draws bounding boxes on an image based on the detection results and saves\n","    the annotated image.\n","\n","    Parameters:\n","    -----------\n","    save_dir : str\n","        The directory where the annotated image will be saved.\n","\n","    file_name : str\n","        The name of the image file (without extension) on which bounding boxes\n","        will be drawn.\n","\n","    detections : list of tuples\n","        A list of detection results, where each detection is a tuple containing\n","        (x1, y1, x2, y2, confidence, class_id).\n","\n","    encode_type : str\n","        The type of encoding used for the image (e.g., \"Height\", \"Height\n","        Difference\", \"Point Count\").\n","\n","    Returns:\n","    --------\n","    numpy.ndarray\n","        The annotated image as a NumPy array in RGB format.\n","    \"\"\"\n","\n","    image_path = (\n","        f\"Processed images/{encode_type} Encoded\"\n","        f\"/{file_name}.png\"\n","    )\n","    output_image = cv2.imread(image_path)\n","\n","    class_colors = {\n","        0 : [0, 255, 255],\n","        1 : [255, 102, 153]\n","    }\n","\n","    for detection in detections:\n","        x1, y1, x2, y2, confidence, class_id = detection\n","        class_id = int(class_id)\n","\n","        # Bounding box\n","        cv2.rectangle(output_image, (x1, y1),\n","                      (x2, y2), class_colors[class_id], 2)\n","\n","        # Label and confidence score\n","        label = f\"{CLASSES[class_id]}: {confidence:.2f}%\"\n","        cv2.putText(output_image, label, (x1, y1 - 10),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, class_colors[class_id], 1)\n","\n","    # Convert image from cv2 to pil format\n","    output_image_rgb = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n","    output_image_pil = Image.fromarray(output_image_rgb)\n","\n","    save_path = (\n","        f\"Outputs/{save_dir}/Labeled Images/\"\n","        f\"[{encode_type}]{file_name}.png\"\n","    )\n","\n","    output_image_pil.save(save_path)\n","\n","    return output_image_rgb"],"metadata":{"id":"BkEkU2tezCS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Coordinate Dump\n","def coord_dump(save_dir, detections, classes):\n","    \"\"\"\n","    Writes detection information, including coordinates, confidence scores,\n","    image filenames, and class labels, to a text file.\n","\n","    Parameters:\n","    -----------\n","    save_dir : str\n","        The directory where the detection information will be saved.\n","\n","    detections : list of tuples\n","        A list of detection results, where each detection is a tuple containing\n","        (center_x, center_y, confidence, image_file, class_id).\n","\n","    classes : dict\n","        A dictionary mapping class IDs to class names.\n","\n","    Returns:\n","    --------\n","    None\n","    \"\"\"\n","\n","    with open(f\"Outputs/{save_dir}/detections.txt\", 'w') as f:\n","        f.write(\"-----------------------------------------------------------\\n\")\n","        f.write(\"|         Info dump on successful detections\\n\")\n","        f.write(\"|  < X >   < Y >   < Confidence >  < Image >   < Class >  |\\n\")\n","        f.write(\"-----------------------------------------------------------\\n\")\n","        for detection in detections:\n","            center_x, center_y, confidence, image_file, class_id = detection\n","\n","            f.write(f\"< {center_x}  {center_y}  {confidence:.2f}\"\n","                    f\"  {image_file}  {classes[class_id]} >\\n\")"],"metadata":{"id":"mx-_ps-rsUf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Detect\n","\n","def run_detections(save_dir, classes, file_list,\n","                   encode_type = \"Height\", seg_size = 512, overlap = 0.1):\n","    \"\"\"\n","    Runs object detection on a list of images by segmenting each image into\n","    smaller parts, applying the model to each segment, and drawing bounding\n","    boxes around detected objects. The function also saves the detection\n","    coordinates to a file.\n","\n","    Parameters:\n","    -----------\n","    save_dir : str\n","        The directory where the results, including annotated images and\n","        detection information, will be saved.\n","\n","    classes : dict\n","        A dictionary mapping class IDs to class names.\n","\n","    file_list : list of str\n","        A list of image filenames (without extensions) to run detections on.\n","\n","    encode_type : str, optional\n","        The type of encoding used for the images (e.g., \"Height\", \"Height\n","        Difference\", \"Point Count\"). Default is \"Height\".\n","\n","    seg_size : int, optional\n","        The size (width and height) of the segments into which each image will\n","        be divided for detection. Default is 512.\n","\n","    overlap : float, optional\n","        The overlap fraction between consecutive segments. Default is 0.1.\n","\n","    Returns:\n","    --------\n","    tuple\n","        A tuple containing two lists:\n","        - total_images: A list of images with drawn bounding boxes (NumPy\n","          arrays).\n","        - file_list: The list of image filenames that were processed.\n","    \"\"\"\n","\n","    model = YOLO(f\"Outputs/{save_dir}/Telefinder_Model.pt\")\n","\n","    total_detections = []\n","    total_images = []\n","\n","    for image_file in file_list:\n","\n","        image = cv2.imread(\n","            f\"Processed images/{encode_type} Encoded/{image_file}.png\")\n","\n","        step_size = int(seg_size * (1 - overlap))\n","        height, width, _ = image.shape\n","        detections = []\n","\n","        for y in range(0, height - seg_size + 1, step_size):\n","            for x in range(0, width - seg_size + 1, step_size):\n","                segment = image[y:y + seg_size, x:x + seg_size]\n","\n","                # Run detection on the segment\n","                results_list = model(segment)\n","\n","                for results in results_list:\n","                    if results.boxes is not None:\n","                        for box in results.boxes:\n","                            x1, y1, x2, y2 = map(int, box.xyxy[0])\n","                            confidence = box.conf[0] * 100\n","                            class_id = int(box.cls[0])\n","\n","                            x1 += x\n","                            y1 += y\n","                            x2 += x\n","                            y2 += y\n","\n","                            center_x = int((x1 + x2) / 2)\n","                            center_y = int((y1 + y2) / 2)\n","\n","                            detections.append([x1, y1, x2, y2,\n","                                               confidence, class_id])\n","                            total_detections.append([center_x,\n","                                                     center_y,\n","                                                     confidence,\n","                                                     image_file,\n","                                                     class_id])\n","\n","        total_images.append(draw_bounding_boxes(save_dir,\n","                                                image_file,\n","                                                detections,\n","                                                encode_type))\n","    coord_dump(save_dir, total_detections, classes)\n","\n","    return total_images, file_list"],"metadata":{"id":"RVG51Z2s0TyT"},"execution_count":null,"outputs":[]}]}